# rodemap

根据比较权威的 [Agent](./Agent) 概念定义和构建流程，要理解 LLM 方向类似 “浏览器输入url到页面展示经历了什么”，就要手搓一个 Agent

[Java+springAI 1.0 大模型应用开发（理论+前后端实践）](https://linux.do/t/topic/753213)

> 😅 前端项目没有特别的AI技术，都是基于接口实现的对话，如果用上一些 AI Chat 组件库、AI 请求工具库，前端基本上只是在提供界面交互给 管理模型选择、管理问答记录、管理提示词、管理MCP配置，这些传统技术实现的东西

- 传统应用：“从已有的数据中找到想要的内容”

- 大模型（Model）：一颗聪明的大脑，能够理解和生成人类语言，“根据提示生成可能的内容”
- 提示词（Prompt）：，通过预设或者用户每次发送的内容作为大模型的输入，影响生成内容走向
- 嵌入（Embeddings）：将文本、图像视频等用数字表示，转换成向量
- 令牌（token）：输入给模型的内容会先转为token，输出也是由token转为内容。（在英语中，一个标记大约相当于一个单词的 75%。作为参考，莎士比亚全集总计约 900,000 字，翻译成大约 120 万个token）
- 记忆（Memory）：模型虽然聪明，但本身不具备记忆功能
- 检索增强生成（RAG）：以更低成本的方式，帮助大模型生成更高质量（知识量、知识时效）的回答
- 多模态（Multimodality）：帮助大模型具备读懂和生成更丰富内容的能力，如图片、音视频等
- 工具调用（Function tool）：帮助大模型 从 “说出来” 到 “动起来”
- 模型上下文协议（MCP）：统一的方式，让大模型"动起来"

Agent能做的事情，在Agent出现之前其实就能做，能带来的好处是什么呢

1. 降低应用开发门槛：无论是写代码、剪辑、还是音视频创作等
2. 简化流程复杂度：区别于传统开发严丝合缝的流程编排，通过大模型强大的理解能力降低流程的构建复杂度
3. 交互方式多样性：agent不局限于自然语言交互，还有多种比如图形界面和动作执行的交互（如代理操作浏览器）
4. 协同完成复杂任务，多个不同的agent进行 组装、协同、竞争，共同参与决策进行合作，达到更好的效果

响应速度慢、幻觉和纯文本交互不优友好等

1. 提升响应速度：芯片提升、模型参数裁剪、模型蒸馏、输入内容预处理（文档切块、Prompt压缩等）
2. 降低幻觉：引导Prompt规范书写、慢思考、GraphRAG、Agent预编译

虽然很多东西属于常识，但要能清晰的表达出来：
以下是一个基础功能的 Chat AI，没有结合到实际的互联网业务中，如果有实际应用场景，chat AI的技术将是基石

1. LLM 选择：云服务商、本地部署
2. 输出方式选择：流式输出、一致性输出
3. 同会话多轮对话的基石：上下文携带、温度等各参数的含义
4. 跨会话（跨设备）上下文携带：memory 记忆
5. 提示词：系统提示词、用户提示词
6. RAG技术: 数据(上下文)向量化存储和检索，知识库是其中的一种应用，成熟的记忆管理也基于RAG技术
7. 多模态：包含：OCR(识字)、图像识别(识物)、音视频
8. Function Call：LLM 使用传统服务
9. MCP：不同标准、不同使用方式的传统服务，配置统一成相同的使用方式

其中 3、4、5 都可以归为上下文功能 (TODO: 使用图来绘制)

## context engineering

- Instructions – prompts, memories, few‑shot examples, tool descriptions, etc
- Knowledge – facts, memories, etc
- Tools – feedback from tool calls

👆 tool 和 memories 定义/描述都归到了 Instructions 里，也没毛病，只有tools返回结果归为tools，一个前置prompt、一个后置的prompt
